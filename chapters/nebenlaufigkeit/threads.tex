% !TeX root = ../../pythonTutorial.tex
\label{threads:section:threads}
\section{Threads}

In Python werden zwei APIs zur Verwendung von Threads angeboten, die Low-Level
API aus dem \_thread-Modul und die Higher-Level API aud dem threading-Modul.
Es wird sich an dieser Stelle auf das threading-Modul beschränkt, da es Intern auf
dem \_thread-Modul basiert und eine Schnittstelle anbietet, welche das Programmieren
von Multithreaded Applikationen erleichert.
Diese Schnittstelle ist an der Thread-Schnittstelle aus Java angelehnt und sollte daher für
Java-Entwickler leicht zu verwenden sein.
Allerdings gibt es einige Unterschiede zwischen dem Python-Modul und der Java-Implementierung.
So sind Bedingungsvariablen und Locks seperate Objekte in Python und es ist auch
nur eine Teilmenge des Verhaltens eine Java-Threads in Python verfügbar.
Ein Python-Thread kennt keine Prioritäten und Thread-Gruppen und er kann nicht zerstört,
gestopped, angehalten, fortgesetzt oder unterbrochen werden.
Soweit vorhanden sind die statischen Methoden aus der Java-Thread-Klasse auf Modul-Ebene
in Python implementiert.

\label{threads:subsection:thread_objekte}
\subsection{Thread Objekte}

Es gibt zwei Möglichkeiten einen Thread zu erzeugen. Entweder wird dem Konstruktor ein
aufrufbares Objekt übergeben,
\label{threads:lst:thread_erzeugung_callable}
\begin{lstlisting}
import threading


def aufgabe():
    # Nebenläufig ausgeführte Aufgabe


thread = threading.Thread(target=aufgabe)
thread.start()
\end{lstlisting}
oder die \lstinline$run()$-Methode wird in einer von \lstinline$Thread$ abgeleiteten Klasse überschrieben.
\label{threads:lst:thread_erzeugung_subclass}
\begin{lstlisting}
import threading


class MeinThread(threading.Thread):
    def run(self):
        # Nebenläufig ausgeführte Aufgabe


thread = MeinThread()
thread.start()
\end{lstlisting}

Der Konstruktor  der \lstinline$Thread$-Klasse bietet noch weitere Parameter an:
\begin{itemize}
    \item \lstinline$group$ sollte immer \lstinline$None$ sein.
    Es ist aktuell reserviert für spätere Erweiterungen.
    \item \lstinline$name$ setzt den Namen des Threads.
    \item \lstinline$args$ ist ein Tupel aus Parameter für das mit \lstinline$target$ definiert
    aufrufbare Objekt.
    \item \lstinline$kwargs$ ist ein Dictionary aus Schlüsselwort-Parameter für \lstinline$target$.
    \item \lstinline$deamon$ setzt die Dämon-Eigenschaft des Threads.
\end{itemize}

Es ist anzumerken, dass ein \lstinline$Thread$-Objekts bei seiner Erzeugung noch nicht gestartet wird.
Hierzu muss explizit die \lstinline$start()$-Methode aufgerufen werden.
Wurde ein Thread gestartet wird er als ''lebendig'' angesehen. 
Dies bleibt er solange, bis seine \lstinline$run()$-Methode verlassen wurde.
Hierbei macht es keinen Unterschied, ob sie regulär verlassen wurde oder Aufgrund einer Exception.
Der aktuelle Status eines Threads kann mittels der \lstinline$is_alive()$-Methode abgefragt werden.
Soll auf das Ende eines anderen Threads gewartet werden, so kann seine
\lstinline$join()$-Methode aufgerufen werden. 
Hiermit wird der aufrufende Thread blockiert, bis der andere beendet ist.
Die \lstinline$join$-Methode nimmt einen optionalen Parameter des Typen \lstinline$float$ entgegen,
der als Timeout in Sekunden dient.
Wird eine Timeout angegeben, ist es wichtig, dass nach dem \lstinline$join()$-Aufruf die Methode 
\lstinline$is_alive()$ aufzurufen.
Da \lstinline$join()$ immer \lstinline$None$ zurückgibt, ist es ansonsten nicht möglich zu wissen, ob
der Thread tatsächlich beendet wurde, oder nur der Timeout abgelaufen ist.

\kontrollfrage{
\item[\kontroll] Wie kann auf das Ende der Ausführung eines Threads gewartet werden?
}

Jeder Thread besitzt einen Namen, welcher initial über den Konstruktor oder direkt über das
\lstinline$name$-Attribut gesetzt werden kann. 
Threads können als Dämon gekennzeichnet werden.
Sobald nur noch Dämon-Threads aktiv sind, wird das Python-Programm beendet.
Die Dämon-Eigenschaft kann initial über den Konstruktor gesetzt werden und übernimmt
den Werte des erzeugenden Threads als Defaultwert.
Über das \lstinline$deamon$-Attribut eines Threads kann die Eigenschaft abgefragt und gesetzt werden.
Hierbei ist es wichtig, dass die Eigenschaft immer vor dem Aufruf der \lstinline$start()$-Methode
gesetzt wird.
Wird sie nach dem Starten des Threads geändert, so wird ein \lstinline$RuntimeError$ geworfen.

\warning{
	Dämon-Threads werden sofort beendet, wenn keine normalen Threads mehr aktiv sind.
	Das heißt, dass ihre Ressourcen wie zum Beispiel geöffnete Dateien oder Datenbanktransaktionen
	gegebenenfalls nicht ordentlich freigegeben werden.
	Um dies zu verhindern sollten die Threads nicht die Dämon-Eigenschaft besitzen und es sollten 
	geeignete Signalisierungsmechanismen eingesetzt werden (siehe \lstinline$Event$-Objekte). %ggf. entfernen falls Kapitel nicht in finaler Abgabe
}

\uebung
\aufgabe{nebenlaufigkeit01}
\aufgabe{nebenlaufigkeit02}


\label{threads:subsection:synchronisation}
\subsection{Synchronisation}

Die meinsten Anwendungen, in denen mehrere Threads zum Einsatz kommen, erfordern einen
Mechanismus, der die Zugriffe der einzelnen Threads auf gewisse Daten synchronisiert.
Hierdurch wird unteranderem vermieden, dass auf invaliden Datensätzen gearbeitet wird, oder ein
Datenupdate verloren geht.
Im Folgenden wird ein Beispiel betrachtet, bei dem es zu Fehlern Aufgrund von fehlender
Synchronisierungsmechanimsen kommt.
Es werden anschließend neue Konstrukte eingeführt, welche die Fehler beheben werden.

Betrachtet wird nun eine Klasse \lstinline$Counter$, welche in Listing
\ref{threads:lst:counter_example} gezeigt wird.
Sie besitzt das Attribut \lstinline$count$, welches durch Aufruf von \lstinline$increment()$
in Einerschritten erhöht wird. 

\label{threads:lst:counter_example}
\lstinputlisting[language=Python,firstline=4,lastline=9]{chapters/nebenlaufigkeit/src/beispiel_synchronisation_fehler.py}

Es ist weiterhin \lstinline$IncrementerThread$ in Listing \ref{threads:lst:incrementer_thread} gegeben,
welcher bei der Initialisierung ein \lstinline$Counter$-Objekt erwartet. Dieser Thread ruft eine Millionen mal die \lstinline$increment()$-Methode des \lstinline$Counters$ auf und beendet sich anschließend.

\label{threads:lst:incrementer_thread}
\lstinputlisting[language=Python,firstline=12,lastline=19]{chapters/nebenlaufigkeit/src/beispiel_synchronisation_fehler.py}

Für dieses Beispiel werden nun 8 \lstinline$IncrementerThreads$ erzeugt und gestartet.
Anschließend wird auf ihre Terminierung gewartet und dann der Wert \lstinline$count$-Attributs des
\lstinline$Counters$ ausgegeben (vgl. Listing \ref{threads:lst:example_no_locks}).

\label{threads:lst:example_no_locks}
\lstinputlisting[language=Python,firstline=22]{chapters/nebenlaufigkeit/src/beispiel_synchronisation_fehler.py}

\kontrollfrage{
\item[\kontroll] Welche Ausgabe würde erwartet werden, wenn 8 Threads den Counter eine Millionen
mal inkrementieren?
}

Dieser Programmcode würde vermuten lassen, dass bei jeder Ausführung der Wert 8000000 ausgegeben
wird, da jeder der 8 Threads den \lstinline$Counter$ eine Millionen mal inkrementiert.
Erstaunlicherweiße werden allerdings bei mehrmaliger Ausführung unterschiedliche Werte ausgegeben.
Diese können zum Beispiel wie folgt aussehen:

\label{threads:lst:beispiel_ausgabe}
\begin{lstlisting}
# Mögliche Ausgaben:
4182858
4377165
3261866
4490102
\end{lstlisting}

Dieses Phänomen lässt sich so erklären, dass die Operation in \lstinline$increment()$ nicht atomar ist.
Genau genommen werden in ihr drei Operationen, eine lesende, eine addierende und eine schreibende,
ausgeführt.
Somit kann es vorkommen, dass zum Beispiel der erste Thread den aktuellen \lstinline$count$-Wert liest
und dann die aktive Ausführung an einen anderen Thread abgeben muss.
Dieser zweite Thread liest nun den selben \lstinline$count$-Wert wie der erste Thread, inkrementiert ihn
und schreibt den neuen Wert zurück in das Attribut.
Nun wechselt die aktive Ausfürhung zurück zum ersten Thread, welche noch den alten \lstinline$count$-Wert gelesen hat.
Dieser alte Wert wird nun erneut inkrementiert und zurückgeschrieben. 
Somit wurde der \lstinline$Counter$ effektiv nicht zweimal sondern nur einmal inkrementiert.
Um dieses Verhalten zu verhindern, muss sichergestellt werden, dass die drei einzelnen Operationen
atomar ausgeführt werden.
Das heißt, dass sie entweder ganz oder garnicht ausgeführt werden.

Als unterste Synchronisationsebene bietet Python die Klasse \lstinline$Lock$ an.
\randnotiz{Locks}
Ein Objekt dieser Klasse befindet sich immer in einem von zwei Zuständen, es ist entweder offen
oder geschlossen.
Nach der Initialisierung befindet es sich zuerst im geöffneten Zustand.
Ein \lstinline$Lock$-Objekt stellt die beiden Methoden \lstinline$acquire()$ und \lstinline$release()$ zur
Verfügung.
Wird \lstinline$acquire()$ auf einem offenen \lstinline$Lock$ aufgerufen, so begibt sich das \lstinline$Lock$
in den geschlossenen Zustand und die Methode kehrt sofort zurück.
Sollte die \lstinline$aquire()$-Methode aufgerufen werden, wenn sich das \lstinline$Lock$ im
geschlossenen Zustand befindet, so blockiert sie solange, bis \lstinline$release()$ in einem anderen Thread
aufgerufen wird und somit den Zustand des \lstinline$Locks$ wieder zu geöffnet ändert.
Die blockierte \lstinline$aquire()$-Methode schließt dann das \lstinline$Lock$ wieder und kehrt zurück.
Wird auf einem offenen \lstinline$Lock$ die \lstinline$release()$-Methode aufgerufen, so wird ein
\lstinline$RuntimeError$ geworfen.
Falls mehrere Threads durch \lstinline$aquire()$ blockiert werden, wird nur ein Thread fortgesetzt sobald
\lstinline$release()$ aufgerufen wurde.
Welcher der blockierten Threads fortgesetzt ist hierbei nicht definiert.

\warning{
Wurde \lstinline$aquire()$ aufgerufen, sollte garantiert sein, dass auch \lstinline$release()$
aufgerufen wird.
Wird eine \lstinline$Exception$ geworfen, kann dies allerdings nicht immer garantiert sein.
Aus diesem Grund wird empfohlen, den synchronisierten Programmcode in einen \lstinline$try$-Block
zu schreiben und den Aufruf von \lstinline$release()$ in den \lstinline$finally$-Block zu schreiben
(vgl. Listing \ref{threads:lst:try_aquire_lock}).
Diese Variante ist allerdings etwas lang und unschön.
Da die \lstinline$Lock$-Klasse das Context-Management-Protokoll unterstützt, kann das gleich mit dem
\lstinline$with$-Block erreicht werden (vgl. Listing \ref{threads:lst:with_aquire_lock}).
Hierbei werden \lstinline$aquire()$ und \lstinline$release()$ automatisch aufgerufen.
}

\label{threads:lst:try_aquire_lock}
\begin{lstlisting}[language=Python]
lock.aquire()
try:
    # kritischer Code
finally:
    lock.release()
\end{lstlisting}
\label{threads:lst:with_aquire_lock}
\begin{lstlisting}[language=Python]
with lock:
    # kritischer Code
\end{lstlisting}

\uebung
\aufgabe{nebenlaufigkeit03}

\randnotiz{Wiedereintrett- bare Schlösser}
\randnotiz{Bedingungs- variablen}
\randnotiz{Semaphoren}
