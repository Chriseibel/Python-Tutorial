% !TeX root = ../../pythonTutorial.tex
\label{threads:section:threads}
\section{Threads}

In Python werden zwei APIs zur Verwendung von Threads angeboten, die Low-Level
API aus dem \_thread-Modul und die Higher-Level API aud dem threading-Modul.
Es wird sich an dieser Stelle auf das threading-Modul beschränkt, da es Intern auf
dem \_thread-Modul basiert und eine Schnittstelle anbietet, welche das Programmieren
von Multithreaded Applikationen erleichert.
Diese Schnittstelle ist an der Thread-Schnittstelle aus Java angelehnt und sollte daher für
Java-Entwickler leicht zu verwenden sein.
Allerdings gibt es einige Unterschiede zwischen dem Python-Modul und der Java-Implementierung.
So sind Bedingungsvariablen und Locks seperate Objekte in Python und es ist auch
nur eine Teilmenge des Verhaltens eine Java-Threads in Python verfügbar.
Ein Python-Thread kennt keine Prioritäten und Thread-Gruppen und er kann nicht zerstört,
gestopped, angehalten, fortgesetzt oder unterbrochen werden.
Soweit vorhanden sind die statischen Methoden aus der Java-Thread-Klasse auf Modul-Ebene
in Python implementiert.

\label{threads:subsection:thread_objekte}
\subsection{Thread Objekte}

Es gibt zwei Möglichkeiten einen Thread zu erzeugen. Entweder wird dem Konstruktor ein
aufrufbares Objekt übergeben,
\label{threads:lst:thread_erzeugung_callable}
\lstinputlisting[language=Python,firstline=4,lastline=9]{chapters/nebenlaufigkeit/src/beispiel_thread_erzeugung.py}
oder die \lstinline$run()$-Methode wird in einer von \lstinline$Thread$ abgeleiteten Klasse überschrieben.
\label{threads:lst:thread_erzeugung_subclass}
\lstinputlisting[language=Python,firstline=12,lastline=18]{chapters/nebenlaufigkeit/src/beispiel_thread_erzeugung.py}

Der Konstruktor  der \lstinline$Thread$-Klasse bietet noch weitere Parameter an:
\begin{itemize}
    \item \lstinline$group$ sollte immer \lstinline$None$ sein.
    Es ist aktuell reserviert für spätere Erweiterungen.
    \item \lstinline$name$ setzt den Namen des Threads.
    \item \lstinline$args$ ist ein Tupel aus Parameter für das mit \lstinline$target$ definiert
    aufrufbare Objekt.
    \item \lstinline$kwargs$ ist ein Dictionary aus Schlüsselwort-Parameter für \lstinline$target$.
    \item \lstinline$deamon$ setzt die Dämon-Eigenschaft des Threads.
\end{itemize}

Es ist anzumerken, dass ein \lstinline$Thread$-Objekts bei seiner Erzeugung noch nicht gestartet wird.
Hierzu muss explizit die \lstinline$start()$-Methode aufgerufen werden.
Wurde ein Thread gestartet wird er als ''lebendig'' angesehen. 
Dies bleibt er solange, bis seine \lstinline$run()$-Methode verlassen wurde.
Hierbei macht es keinen Unterschied, ob sie regulär verlassen wurde oder Aufgrund einer Exception.
Der aktuelle Status eines Threads kann mittels der \lstinline$is_alive()$-Methode abgefragt werden.
Soll auf das Ende eines anderen Threads gewartet werden, so kann seine
\lstinline$join()$-Methode aufgerufen werden. 
Hiermit wird der aufrufende Thread blockiert, bis der andere beendet ist.
Die \lstinline$join$-Methode nimmt einen optionalen Parameter des Typen \lstinline$float$ entgegen,
der als Timeout in Sekunden dient.
Wird eine Timeout angegeben, ist es wichtig, dass nach dem \lstinline$join()$-Aufruf die Methode 
\lstinline$is_alive()$ aufzurufen.
Da \lstinline$join()$ immer \lstinline$None$ zurückgibt, ist es ansonsten nicht möglich zu wissen, ob
der Thread tatsächlich beendet wurde, oder nur der Timeout abgelaufen ist.

\kontrollfrage{
\item[\kontroll] Wie kann auf das Ende der Ausführung eines Threads gewartet werden?
}

Jeder Thread besitzt einen Namen, welcher initial über den Konstruktor oder direkt über das
\lstinline$name$-Attribut gesetzt werden kann. 
Threads können als Dämon gekennzeichnet werden.
Sobald nur noch Dämon-Threads aktiv sind, wird das Python-Programm beendet.
Die Dämon-Eigenschaft kann initial über den Konstruktor gesetzt werden und übernimmt
den Werte des erzeugenden Threads als Defaultwert.
Über das \lstinline$deamon$-Attribut eines Threads kann die Eigenschaft abgefragt und gesetzt werden.
Hierbei ist es wichtig, dass die Eigenschaft immer vor dem Aufruf der \lstinline$start()$-Methode
gesetzt wird.
Wird sie nach dem Starten des Threads geändert, so wird ein \lstinline$RuntimeError$ geworfen.

\warning{
	Dämon-Threads werden sofort beendet, wenn keine normalen Threads mehr aktiv sind.
	Das heißt, dass ihre Ressourcen wie zum Beispiel geöffnete Dateien oder Datenbanktransaktionen
	gegebenenfalls nicht ordentlich freigegeben werden.
	Um dies zu verhindern sollten die Threads nicht die Dämon-Eigenschaft besitzen und es sollten 
	geeignete Signalisierungsmechanismen eingesetzt werden (siehe \lstinline$Event$-Objekte). %ggf. entfernen falls Kapitel nicht in finaler Abgabe
}

\uebung
\aufgabe{nebenlaufigkeit01}
\aufgabe{nebenlaufigkeit02}


\label{threads:subsection:synchronisation}
\subsection{Synchronisation}

Die meinsten Anwendungen, in denen mehrere Threads zum Einsatz kommen, erfordern einen
Mechanismus, der die Zugriffe der einzelnen Threads auf gewisse Daten synchronisiert.
Hierdurch wird unteranderem vermieden, dass auf invaliden Datensätzen gearbeitet wird, oder ein
Datenupdate verloren geht.
Im Folgenden wird ein Beispiel betrachtet, bei dem es zu Fehlern Aufgrund von fehlender
Synchronisierungsmechanimsen kommt.
Es werden anschließend neue Konstrukte eingeführt, welche die Fehler beheben werden.

Betrachtet wird nun eine Klasse \lstinline$Counter$, welche in Listing
\ref{threads:lst:counter_example} gezeigt wird.
Sie besitzt das Attribut \lstinline$count$, welches durch Aufruf von \lstinline$increment()$
in Einerschritten erhöht wird. 

\label{threads:lst:counter_example}
\lstinputlisting[language=Python,firstline=4,lastline=9]{chapters/nebenlaufigkeit/src/beispiel_synchronisation_fehler.py}

Es ist weiterhin \lstinline$IncrementerThread$ in Listing \ref{threads:lst:incrementer_thread} gegeben,
welcher bei der Initialisierung ein \lstinline$Counter$-Objekt erwartet. Dieser Thread ruft eine Millionen mal die \lstinline$increment()$-Methode des \lstinline$Counters$ auf und beendet sich anschließend.

\label{threads:lst:incrementer_thread}
\lstinputlisting[language=Python,firstline=12,lastline=19]{chapters/nebenlaufigkeit/src/beispiel_synchronisation_fehler.py}

Für dieses Beispiel werden nun 10 \lstinline$IncrementerThreads$ erzeugt und gestartet.
Anschließend wird auf ihre Terminierung gewartet und dann der Wert \lstinline$count$-Attributs des
\lstinline$Counters$ ausgegeben (vgl. Listing \ref{threads:lst:example_no_locks}).

\label{threads:lst:example_no_locks}
\lstinputlisting[language=Python,firstline=22]{chapters/nebenlaufigkeit/src/beispiel_synchronisation_fehler.py}

\kontrollfrage{
\item[\kontroll] Welche Ausgabe würde erwartet werden, wenn 10 Threads den Counter eine Millionen
mal inkrementieren?
}

Dieser Programmcode würde vermuten lassen, dass bei jeder Ausführung der Wert 10000000 ausgegeben
wird, da jeder der 10 Threads den \lstinline$Counter$ eine Millionen mal inkrementiert.
Erstaunlicherweiße werden allerdings bei mehrmaliger Ausführung unterschiedliche Werte ausgegeben.
Diese können zum Beispiel wie folgt aussehen:

\label{threads:lst:beispiel_ausgabe}
\begin{lstlisting}
# Mögliche Ausgaben:
5237496
3561559
4089438
4526494
\end{lstlisting}

Dieses Phänomen lässt sich so erklären, dass die Operation in \lstinline$increment()$ nicht atomar ist.
Genau genommen werden in ihr drei Operationen, eine lesende, eine addierende und eine schreibende,
ausgeführt.
Somit kann es vorkommen, dass zum Beispiel der erste Thread den aktuellen \lstinline$count$-Wert liest
und dann die aktive Ausführung an einen anderen Thread abgeben muss.
Dieser zweite Thread liest nun den selben \lstinline$count$-Wert wie der erste Thread, inkrementiert ihn
und schreibt den neuen Wert zurück in das Attribut.
Nun wechselt die aktive Ausfürhung zurück zum ersten Thread, welche noch den alten \lstinline$count$-Wert gelesen hat.
Dieser alte Wert wird nun erneut inkrementiert und zurückgeschrieben. 
Somit wurde der \lstinline$Counter$ effektiv nicht zweimal sondern nur einmal inkrementiert.
Um dieses Verhalten zu verhindern, muss sichergestellt werden, dass die drei einzelnen Operationen
atomar ausgeführt werden.
Das heißt, dass sie entweder ganz oder garnicht ausgeführt werden.

Als unterste Synchronisationsebene bietet Python die Klasse \lstinline$Lock$ an.
\randnotiz{Locks}
Ein Objekt dieser Klasse befindet sich immer in einem von zwei Zuständen, es ist entweder offen
oder geschlossen.
Nach der Initialisierung befindet es sich zuerst im geöffneten Zustand.
Ein \lstinline$Lock$-Objekt stellt die beiden Methoden \lstinline$acquire()$ und \lstinline$release()$ zur
Verfügung.
Wird \lstinline$acquire()$ auf einem offenen \lstinline$Lock$ aufgerufen, so begibt sich das \lstinline$Lock$
in den geschlossenen Zustand und die Methode kehrt sofort zurück.
Sollte die \lstinline$aquire()$-Methode aufgerufen werden, wenn sich das \lstinline$Lock$ im
geschlossenen Zustand befindet, so blockiert sie solange, bis \lstinline$release()$ in einem anderen Thread
aufgerufen wird und somit den Zustand des \lstinline$Locks$ wieder zu geöffnet ändert.
Die blockierte \lstinline$aquire()$-Methode schließt dann das \lstinline$Lock$ wieder und kehrt zurück.
Wird auf einem offenen \lstinline$Lock$ die \lstinline$release()$-Methode aufgerufen, so wird ein
\lstinline$RuntimeError$ geworfen.
Falls mehrere Threads durch \lstinline$aquire()$ blockiert werden, wird nur ein Thread fortgesetzt sobald
\lstinline$release()$ aufgerufen wurde.
Welcher der blockierten Threads fortgesetzt ist hierbei nicht definiert.

Wurde \lstinline$aquire()$ aufgerufen, sollte garantiert sein, dass auch \lstinline$release()$
aufgerufen wird.
Wird eine \lstinline$Exception$ geworfen, kann dies allerdings nicht immer garantiert sein.
Aus diesem Grund wird empfohlen, den synchronisierten Programmcode in einen \lstinline$try$-Block
zu schreiben und den Aufruf von \lstinline$release()$ in den \lstinline$finally$-Block zu schreiben
(vgl. Listing \ref{threads:lst:try_aquire_lock}).
\label{threads:lst:try_aquire_lock}
\lstinputlisting[language=Python,firstline=5,lastline=9]{chapters/nebenlaufigkeit/src/beispiel_lock_aquire_release.py}

Diese Variante ist allerdings etwas lang und unschön.
Da die \lstinline$Lock$-Klasse das Context-Management-Protokoll unterstützt, kann das gleich mit dem
\lstinline$with$-Block erreicht werden (vgl. Listing \ref{threads:lst:with_aquire_lock}).
Hierbei werden \lstinline$aquire()$ und \lstinline$release()$ automatisch aufgerufen.
\label{threads:lst:with_aquire_lock}
\lstinputlisting[language=Python,firstline=11,lastline=12]{chapters/nebenlaufigkeit/src/beispiel_lock_aquire_release.py}

Wird \lstinline$aquire()$ ohne Parameter aufgerufen, blockiert sie solange, bis \lstinline$release()$ 
aufgerufen wird.
Ist dies nicht gewünscht, so kann auch der optionale Parameter \lstinline$blocking=False$ angegeben
werden. 
In diesem Fall kehrt \lstinline$aquire()$ sofort zurück, egal in welchem Zustand sich das \lstinline$Lock$
befindet.
Es muss nun der Rückgabewert von \lstinline$aquire()$ betrachtet werden, um zu wissen, ob das 
\lstinline$Lock$ offen oder geschlossen ist.
Ist das \lstinline$Lock$ bereits geschlossen wird der Wert \lstinline$False$ zurückgegeben.
Andernfalls wird \lstinline$True$ zurückgegeben und das \lstinline$Lock$ ändert seinen Zustand zu
geschlossen.
Weiterhin ist es möglich, einen Timeout mittels des optionalen Parametes \lstinline$timeout$ zu 
spezifizieren.
Hierbei kann eine beliebige Zeit in Sekunden als \lstinline$float$ Wert angegeben werden.
In diesem Fall blockiert \lstinline$aquire()$ maximale die spezifizierte Zeit.
Wurde in dieser Zeit das \lstinline$Lock$ erlangt, so gibt \lstinline$aquire()$ \lstinline$True$ zurück,
andernfalls \lstinline$False$.
Die Angabe eines Timeouts ist nur erlaubt, wenn der Parameter \lstinline$blocking$ den Wert
\lstinline$True$ besitzt.

\uebung
\aufgabe{nebenlaufigkeit03}
\aufgabe{nebenlaufigkeit04}

Um das Problem aus Aufgabe \ref{nebenlaufigkeit04} zu lösen bietet Python eine weitere Möglichkeit
zur Synchronisation an.
\randnotiz{Reentrant Locks}
Hierbei handelt es sich um die \lstinline$RLock$-Klasse.
Das \lstinline$R$ steht für \lstinline$reentrant$, was auf deutsch Wiedereintritt bedeutet.
Im Gegensatz zu Objekten der \lstinline$Lock$-Klasse, die nie einem Thread zugeordnet werden, werden
Objekte der \lstinline$RLock$-Klasse an den Thread gebunden, der zuerst die \lstinline$aquire()$-Methode
aufruft.
Neben den beiden Zuständen, die die \lstinline$Lock$-Klasse besitzt, merkt sich die \lstinline$RLock$-Klasse
nun auch, wie oft die \lstinline$aquire()$-Methode aufgerufen wurde.
Beim ersten Aufruf von \lstinline$aquire()$ merkt sich das \lstinline$RLock$-Objekt, welcher Thread die
Methode aufgerufen hat und setzt einen internen Zähler auf 1.
Bei jedem weiteren Aufruf von \lstinline$aquire()$ des selben Threads wird der Zähler inkrementiert.
Wird \lstinline$release()$ aufgerufen, so wird der Zähler wieder dekrementiert.
Das \lstinline$RLock$ ist erst dann wieder offen, wenn \lstinline$release()$ so oft aufgerufen wurde wie
\lstinline$aquire()$ und der interne Zähler wieder auf 0 steht.
Ruft ein zweiter Thread die \lstinline$aquire()$-Methode auf, während der erste Thread das
\lstinline$RLock$ besitzt, so muss er warten, bis der Zähler wieder auf 0 steht.
Es ist nun also möglich einen gewissen Codeabschnitt auch rekursive vor konkurrierenden Zugriffen 
zu schützen.
Wie auch schon beim \lstinline$Lock$, können der \lstinline$aquire()$-Methode des \lstinline$RLocks$ 
die beiden optionalen Paramter \lstinline$blocking$ und \lstinline$timeout$ mitgegeben werden.

\uebung
\aufgabe{nebenlaufigkeit05}

Im Folgenden wird das Beispiel mit dem \lstinline$Counter$ und dem \lstinline$IncrementerThread$
etwas angepasst.
Der \lstinline$IncrementerThread$ soll nun den \lstinline$Counter$ wieder immer nur um eins erhöhen.
Weiterhin wird dem \lstinline$IncrementerThread$ ein Wert übergeben, mit welchem gesteuert wird,
wann der Thread den \lstinline$Counter$ erhöht. Den 10 erstellten \lstinline$IncrementerThreads$ 
wird nun eine Zahl von 0 bis 9 übergeben. Der \lstinline$Counter$ soll von den einzelnen Threads immer
nur dann erhöht werden, wenn der aktuelle Wert des \lstinline$Counters$ auf die Ziffer endet, die dem
Thread bei der Erzeugung übergeben wurde.
Demnach müssen die \lstinline$IncrementerThreads$ auf einen bestimmten geteilten Zustand warten,
bevor sie \lstinline$increment()$ aufrufen dürfen.
\randnotiz{Condition-Variable}
Für einen solchen Anwendungsfall stellt Python die \lstinline$Condition$-Klasse zur Verfügung, welche
einen Mechanismus implementiert, der allgemein als Condition Variable (deutch Bedingungsvariable)
bekannt ist.
Objekte der \lstinline$Condition$-Klasse sind immer einem \lstinline$Lock$- oder einem
\lstinline$RLock$-Objekt zugeordnet.
Dieses kann dem Konstruktor eines \lstinline$Condition$-Objektes übergeben werden.
Wird kein Lock-Objekt übergeben, erzeugt der Konstruktor ein neues.
Das so erzeugte \lstinline$Condition$-Objekt kann nun überall wie zuvor das Lock-Objekt
verwendet werden, das Lock-Objekt muss nicht weiterhin zusätzlich verwaltet werden.
Es kann nun also das \lstinline$RLock$ aus der \lstinline$Counter$-Klasse gegen eine Condition Variable
ausgetauscht werden.
Die neue \hyperref[threads:lst:counter_condition_variable_example]{\lstinline$Counter$-Klasse} sieht
dann wie folgt aus:
\label{threads:lst:counter_condition_variable_example}
\lstinputlisting[language=Python,firstline=4,lastline=15]{chapters/nebenlaufigkeit/src/beispiel_condition_variable.py}

Eine Condition Variable kann also wie ein einfaches Lock verwendet werden.
Die \lstinline$aquire()$- und \lstinline$release()$-Methoden verhalten sich hierbei, wie die des hinterlegten
Lock-Objektes.
Darüber hinaus bietet die \lstinline$Condition$-Klasse noch weitere Methoden an.
Diese Methoden dürfen nur aufgerufen werden, wenn zuvor \lstinline$aquire()$ aufgerufen wurde.
Wurde von einem Thread \lstinline$aquire()$ aufgerufen, aber der aktuelle geteilte Zustand
nicht den gewünschten Bedingungen entspricht, so wird \lstinline$wait()$ aufgerufen.
Die \lstinline$wait()$-Methode gibt das Lock wieder frei und blockiert dann den Thread, bis er
aufgeweckt wird.
Ein Thread wird durch Aufruf der \lstinline$notify()$- oder der \lstinline$notifiy_all()$-Methode aufgeweckt.
Diese Methoden sollten immer dann aufgerufen werden, wenn der geteilte Zustand von einem Thread 
geändert wurde.
Sobald ein Thread aufgeweckt wurde, fordert \lstinline$wait()$ wieder das Schloss an und kehrt
dann zurück.
Nachdem \lstinline$wait()$ zurückgekehrt ist, sollten die Bedingungen an den geteilten Zustand auf 
jeden Fall wieder geprüft werden, da eine unbestimmte Zeit zwischen dem Aufruf von \lstinline$notify()$
oder \lstinline$notify_all()$ und dem Zurückkehren von \lstinline$wait()$ vergehen kann.
Weiterhin ist es möglich \lstinline$wait()$ den optionalen Parameter \lstinline$timeout$ mitzugeben.
Läuft diese Zeit ab, bevor ein anderer Thread \lstinline$notify()$ oder \lstinline$notify_all()$ aufruft,
kehrt \lstinline$wait()$ mit dem Rückgabewert \lstinline$False$ zurück.

\tip{
Um die Entscheidung zwischen \lstinline$notify()$ und \lstinline$notify_all()$ zu erleichtern, sollte die Frage
gestellt werden, ob die Änderung des geteilten Zustands für nur einen Thread oder mehrere Threads
interessant ist.
}

Durch einen Aufruf von \lstinline$notify_all()$ werden alle Threads, die \lstinline$wait()$ auf dem
entsprechenden \lstinline$Condition$-Objekt aufgerufen haben, aufgeweckt.
Mit \lstinline$notify()$ wird nur ein Thread aufgeweckt.
Es kann ein optionaler Parameter \lstinline$n$ an \lstinline$notify()$ übergeben werden, der angibt, wie
viele Threads aufgeweckt werden sollen.

\warning{
	Durch den Aufruf von \lstinline$notify()$ und \lstinline$notify_all()$ wird das Lock nicht freigegeben.
	Das heißt, dass Threads, die \lstinline$wait()$ aufgerufen haben, erst dann wieder aufwachen, wenn
	der Thread, der \lstinline$notify()$ oder \lstinline$notify_all()$ aufgerufen hat das Lock wieder 
	explizit freigibt.
}

Wie das generische \hyperref[threads:lst:producer_consumer]{Producer-Consumer-Pattern}
mithilfe von Condition Variablen implementiert werden kann, ist im folgenden Listing
gezeigt \cite{pythondokuthreads}.
Die Consumer warten so lange, bis der geteilte Zustand der Bedingung entspricht.
In diesem Fall heißt das, dass mindestens ein Element verfügbar ist.
Sobald ein Producer ein Element erstellt hat, ruft er \lstinline$notify()$ auf.
Somit wird genau ein Consumer aufgeweckt.
In diesem Beispiel reicht es vollkommen aus, nur einen Consumer aufzuwecken.
Es gibt allerdings auch Fälle, in denen es nicht ausreicht, nur einen beliebigen Consumer zu wecken.
Das \lstinline$Counter$ und \lstinline$IncrementerThread$ Beispiel würde nicht funktionieren, wenn 
immer nur ein beliebiger Thread geweckt wird. 

\kontrollfrage{
\item[\kontroll] Warum ist es in diesem Beispiel nicht ausreichend, \lstinline$notify()$ aufzurufen?
}

In diesem Fall muss bei einer Änderung des geteilten Zustandes \lstinline$notify_all()$ aufgerufen werden,
um einen Deadlock zu vermeiden.
Dies liegt daran, das immer nur genau ein wartender Thread fortschreiten kann und es ist nicht
garantiert werden kann, dass genau dieser Thread aufgeweckt wird.

\label{threads:lst:producer_consumer}
\lstinputlisting[language=Python,firstline=21,lastline=30]{chapters/nebenlaufigkeit/src/beispiel_producer_consumer.py}

Im Beispiel zum \hyperref[threads:lst:producer_consumer]{Producer-Consumer-Pattern} ruft der
Consumer \lstinline$wait()$ innerhalb der \lstinline$while$-Schleife auf und prüft jedes mal seine
Bedingung.
Dies ist notwendig, da sich der Zustand zwischen dem Aufruf von \lstinline$notify()$ und dem 
Zurückkehren von \lstinline$wait()$ erneut ändern kann. 
Diese Problematik ist inhärent in der Multithreaded-Programmierung.
Die \lstinline$Condition$-Klasse bietet neben \lstinline$wait()$ eine weitere Methode an, die das Testen
der Bedingung automatisieren kann.
Bei dieser Methode handelt es sich um \lstinline$wait_for()$.
Ihr Paramater \lstinline$predicate$ nimmt ein Callable-Objekt entgegen, welches einen boolischen Wert
zurück gibt.
Es kann zudem ein Timeout angegeben werden, der sich wie bei \lstinline$wait()$ verhält.
Wird \lstinline$wait_for()$ verwendet, ändert sich das
\hyperref[threads:lst:producer_consumer_wait_for]{Producer-Consumer-Pattern Beispiel}
folgender Maßen \cite{pythondokuthreads}:

\label{threads:lst:producer_consumer_wait_for}
\lstinputlisting[language=Python,firstline=32,lastline=35]{chapters/nebenlaufigkeit/src/beispiel_producer_consumer.py}

\uebung
\aufgabe{nebenlaufigkeit06}

\randnotiz{Semaphoren}
